<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Micah Roberson]]></title>
  <link href="http://micahroberson.com/atom.xml" rel="self"/>
  <link href="http://micahroberson.com/"/>
  <updated>2013-10-04T12:39:14-07:00</updated>
  <id>http://micahroberson.com/</id>
  <author>
    <name><![CDATA[Micah Roberson]]></name>
    <email><![CDATA[micah.roberson@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Upload files directly to S3 w/ Backbone on Heroku]]></title>
    <link href="http://micahroberson.com/upload-files-directly-to-s3-w-backbone-on-heroku/"/>
    <updated>2013-10-04T09:40:00-07:00</updated>
    <id>http://micahroberson.com/upload-files-directly-to-s3-w-backbone-on-heroku</id>
    <content type="html"><![CDATA[<p><a href="http://aws.amazon.com/s3/">S3</a> has been the defacto standard for some time now when it comes to cloud storage, specifically for handling user uploads. PaaS providers often have limitations on storage and/or file uploads &ndash; most notably Heroku, which doesn&rsquo;t allow any file writes outside of the /tmp directory. Fortunately this is an easy enough problem to solve, with help from <a href="https://github.com/thoughtbot/paperclip">Paperclip</a> and <a href="https://github.com/carrierwaveuploader/carrierwave">CarrierWave</a>. Although utilizing one of these options may be easy and not all that different from how you would handle user uploads in a classic Rails app where you CAN write to the filesystem, they aren&rsquo;t all that efficient on Heroku. A simple file upload becomes a data-intesive, long-drawn-out request in order to get the file from the browser(client) to the server(Heroku) and then to S3. Ideally these gems would process the file(s) in the background, and we could say the time to do so is negligible as a result. But when we decide we want to show progress to the user and also know when the upload is complete, things get a lot more complicated!</p>

<p>This solution was originally built by Rok Krulec at <a href="http://dubjoy.com">Dubjoy</a>, and can be found here: <a href="http://codeartists.com/post/36892733572/how-to-directly-upload-files-to-amazon-s3-from-your">http://codeartists.com/post/36892733572/how-to-directly-upload-files-to-amazon-s3-from-your</a>, but I&rsquo;ve forked the code and made some tweaks to handle multiple files, progress, and cancellations.</p>

<p>In order to implement the entirety of this setup, you&rsquo;ll need a CORS enabled bucket. Follow <a href="http://codeartists.com/post/36892733572/how-to-directly-upload-files-to-amazon-s3-from-your">Step 1</a> for instructions. You&rsquo;ll also need to setup server-side request signing, which Rok Krulec shows how to do in <a href="http://codeartists.com/post/36892733572/how-to-directly-upload-files-to-amazon-s3-from-your">Step 3</a>.</p>

<p>For the client-side implementation, which is Step 2 from the blog post linked above, we&rsquo;ll do things a little differently.</p>

<p>You can find my forked repo with the necessary S3Upload lib here: <a href="https://github.com/micahroberson/s3upload-coffee-javascript">https://github.com/micahroberson/s3upload-coffee-javascript</a></p>

<p>To a Backbone view I&rsquo;ve added the following:</p>

<pre><code># Listener to detect when the user has selected a file.
# We could also opt for a click event on an 'Upload Files' button instead
events:
  'change input#Files': 'onChangeFiles'

...

# Listen for newly added models and render a view for each
initialize: () -&gt;
  @listenTo @attachmentsCollection, 'add', @onAddAttachment
...

# Instantiate and render new views for models added to the collection
# This is the view that will be listening to the 'upload:progress' event, and can also allow the user to cancel the upload
onAddAttachment: (model, response) -&gt;
  attachmentView = new Doozie.Views.Attachments.Show(model: model)
  @$('.card-attachments').append(attachmentView.render().el)
  @attachmentViews[model.cid] = attachmentView

...

# Callback bound above which triggers the actual upload via the S3Upload lib
onChangeFiles: (e) -&gt;
  return if $(e.target).val() == ''

  @uploadToS3
    files_dropped: false,
    file_dom_selector: '#Files'

...

# Instantiation of a new S3Upload with custom callbacks
uploadToS3: (options) -&gt;
  # We create an object to store the newly created models for reference in progress and abort callbacks
  newAttachments = {}
  s3upload = new S3Upload
    # files_dropped and file_list are only necessary for handling drag and drop uploads, which we'll address later
    files_dropped: options.files_dropped,
    file_list: options.file_list,
    file_dom_selector: options.file_dom_selector,
    s3_sign_put_url: '/api/attachments/signput',

    onProgress: (xhr, file, percent, message) =&gt;
      # Create a new Attachment model for the file which has just started uploading, otherwise trigger an 'upload:progress' event on the model which a view can listen for
      if percent == 0
        attachment = new Doozie.Models.Attachment
          name : file.name, 
          s3_url: '', 
          card_id : @model.id,
          project_id: @model.get('project_id'),
          file_type : file.type, 
          size : parseFloat(file.size)
        # Key on file.size for uniqueness
        newAttachments[file.size] = attachment
        # Add the model to the Backbone collection, which will trigger an 'add' event
        @attachmentsCollection.add(attachment)
      else
        attachment = newAttachments[file.size]
        if attachment
          attachment.trigger('upload:progress', { percent: percent, message: message, xhr: xhr })

    onAbort: (file, message) =&gt;
      attachment = newAttachments[file.size]
      attachment.destroy()
      delete newAttachments[file.size]
      # Must replace old input type=file. for some reason, it doesn't clear the value
      @$('input#Files').replaceWith("&lt;input id='files' type='file' name='files[]' multiple /&gt;")

    onFinishS3Put: (public_url, file) =&gt;
      # Grab the attachment model and update it with the final url
      # Also note that the model has not yet been saved, so the backend would be unaware of a cancelled upload
      attachment = newAttachments[file.size]
      attachment.save({ s3_url: public_url })

    onError: (file, status) =&gt;
      console.log('Upload error: ', status)
      attachment = newAttachments[file.size]
      attachment.destroy()
      delete newAttachments[file.size]
</code></pre>

<p>The attachment view(s) instantiated above looks like this:</p>

<pre><code>...

events: 
  'click .cancel' : 'onCancelUpload'

initialize: () -&gt;
  @listenTo(@model, 'upload:progress', @onUploadProgress)
  @listenTo(@model, 'destroy', @destroy)

onUploadProgress: (data) -&gt;
  @$('.progress .meter').css('width', "#{data.percent}%")

  if data.percent == 100
    # If the upload is complete, remove the progress bar and cancel button
    @$('.progress, .cancel').remove()
    @_xhr = null
  else if !@_xhr
    # Else if @_xhr is not yet defined, save a reference to it
    @_xhr = data.xhr

onCancelUpload: (e) -&gt;
  # Leverage the saved xhr reference to abort() the upload
  if @_xhr
    @_xhr.abort()
</code></pre>

<p>On the Rails side of things, we&rsquo;re really only storing the S3 url and a few other details about the file that we may want to display. The most important piece here is the after_destroy callback to actually delete the S3 object when the model is destroyed. Note that this uses the &lsquo;aws-sdk&rsquo; gem.</p>

<pre><code>class Attachment
  include Mongoid::Document
  include Mongoid::Timestamps

  field :name, type: String
  field :s3_url, type: String
  field :file_type, type: String
  field :size, type: Float

  belongs_to :creator, class_name: 'User', inverse_of: nil
  belongs_to :card, inverse_of: :blobs, touch: true

  after_destroy :delete_from_s3

  def delete_from_s3
    s3 = AWS::S3.new access_key_id: ENV['S3_ACCESS_KEY'], secret_access_key: ENV['S3_SECRET_KEY']
    key = s3_url.sub("https://s3.amazonaws.com/#{ENV['S3_BUCKET_NAME']}/", "")
    s3.buckets[ENV['S3_BUCKET_NAME']].objects[key].delete
  end

end
</code></pre>

<p>And that&rsquo;s all there is to it! We&rsquo;ve built a simple and efficient solution that allows users to upload multiple files at the same time, see indiviual progress bars for each file and also cancel each file independently. To take this a little further we can allow users to drag files onto the view and trigger an upload, and also create a proxy route for downloading files, which hides the actual S3 url.</p>

<p>To upload files on &lsquo;drop&rsquo;, just add the following event listener and handler, and it will trigger the same sequence of events as with the file type input.</p>

<pre><code>events: 
  'drop'  :  'onDrop'

onDrop: (e) -&gt;
  return if e.dataTransfer == null

  @uploadToS3({
    files_dropped: true,
    file_list: e.dataTransfer.files
  });
</code></pre>

<p>For the download link, we just use a controller action mapped to /attachments/download/:id</p>

<pre><code>def download
  @attachment = Attachment.where( company_id: current_user.company_id, id: params[:id] ).first
  data = open URI.parse(@attachment.s3_url)
  send_data data.read, filename: "#{@attachment.name}", type: "#{@attachment.file_type}", disposition: 'inline', stream: 'true', buffer_size: '4096'
end
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Saving Drag and Drop Sort Position]]></title>
    <link href="http://micahroberson.com/saving-drag-and-drop-sort-position/"/>
    <updated>2013-09-25T10:35:00-07:00</updated>
    <id>http://micahroberson.com/saving-drag-and-drop-sort-position</id>
    <content type="html"><![CDATA[<p>We recently began work on an in-house solution for managing our projects at <a href="https://www.readyappsdev.com">ReadyApps</a>, and this solution requires that we have the ability to drag and drop &lsquo;cards&rsquo; in the same light as Trello or Blossom. Drag and drop interfaces are certainly nothing new and neither is rearranging the position of an element in a sorted array. However, I was unable to find much information on doing this in the most efficient way possible from a client-side javascript application.</p>

<p><img class="width-100" src="http://micahroberson.com/images/dragndrop.png"></p>

<p>I considered the following factors/constraints when determining the best implementation:</p>

<ul>
<li>Update new position(s) with a single ajax call</li>
<li>Allow for consecutive client-side moves without having to redraw the entire list after each move</li>
<li>Minimize backend work to save a move</li>
<li>Minimize backend work to retrieve cards from database and sort into proper order</li>
<li>Allow for real-time client-side updates from other users (ie. card position changes via websockets)</li>
<li>There should be no limit to the number of times a user can rearrage a set of cards</li>
<li>The solution should allow for a sufficiently high number of cards to be sorted and retrieved in decent amount of time</li>
</ul>


<p>The simplest solution would be to simply store a &lsquo;position&rsquo; on each card as an integer and sort by that column when retrieving from the database. However, this solution would require that dragging Card A from position 8 to position 1 would need to update all cards with position > 1. Although the query is trivial, these cards would need to be updated client-side as well in order to maintain a clean state. Clean state is important for allowing consecutive moves as well as updates from websockets.</p>

<p>Another solution is to store the sort order outside of the actual cards &ndash; ie. an array of card ids on the project model. I would prefer the order to be saved on the actual card (for API purposes, it makes more sense to be able to sort the cards without having the actual project model as well), this method also requires that we redraw every card on a change. I suppose we could diff the arrays client-side and determine which cards need to be moved, but I haven&rsquo;t actually thought it through enough to be sure that would work efficiently.</p>

<p>The runner-up solution was to store the position on a card but as a double rather than an integer. Keeping this value a double means we can simply set the new position to half of the difference between the two cards. Moving a card from position 8 to position 1(assuming all cards have integer positions at this point), we would set the new position to (1 &ndash; 0) / 2 = 0.5. This would require a single save on the card that changed position, and we could still sort on the position column when retrieving the data. This also allows for handling position changes from other users via websockets. The one limitation is the number of rearrangements a user can make. Eventually we&rsquo;re going to max out the decimal places on the double. We could re-sort all of the elements with a background job when the cards approach this limit, but that doesn&rsquo;t seem like the right way to solve the problem.</p>

<p>The solution we ended up going with is to simulate a linked-list in order to maintain relevent position. Each card stores the id of the card it follows. This makes client-side updates extremely easy: if a card model changes, we simply find the id it follows and append it right after. As far as the client knows, only a single ajax call is required. Server-side, there&rsquo;s actually two more operations that need to take place: updating the new follower of the card that moved, and updating the previous follower of the card that moved. When retrieving the data server-side, we can put all of the cards in order with a simple loop. Although the operation isn&rsquo;t linear, the complexity is roughly O(n log n) &ndash; on par with mergesort. Some quick benchmarking showed the following results:</p>

<ul>
<li>0.001941s for 10 cards</li>
<li>0.205871s for 500 cards</li>
<li>0.812723s for 1000 cards</li>
</ul>


<p>Although it starts to climb quickly upwards of 1000 cards, its highly unlikely that a user would ever add that many cards and still expect good performance, so we&rsquo;re content with the results.</p>

<p>Implementing the solution client-side with <a href="http://www.backbonejs.org">Backbone.js</a> and <a href="http://www.jqueryui.com">jQuery UI</a> is done with the following method to be called after a card is &lsquo;dropped&rsquo;:</p>

<pre><code>updatePositions: (e, ui) =&gt;
  $ui = ui.item
  id = $ui.data('model-id')
  $after = $ui.prev()

  afterCardId = if $after then $after.data('model-id') else null

  card = @cardsCollection.get(id)
  card.save(
    after_card_id: afterCardId
    )
</code></pre>

<p>Server-side we&rsquo;ll add a method to be called after updating the after_card_id(ID of the preceding card, nil if first) of the card that moved:</p>

<pre><code>def update_after_card(stage_id_was, after_card_id_was)
  # Update card that previously came after
  Card.where(after_card_id: id).update_all(
    after_card_id: after_card_id_was
    )

  # Update card that now comes after
  Card.where(:id.ne =&gt; id).where(after_card_id: after_card_id).update_all(
    after_card_id: id
    )
end
</code></pre>

<p>Also server-side we can retrieve the data from a MongoDB backed Rails app as follows (this was a very quick implementation and there are definitely some improvements that could be made to improve the efficiency):</p>

<pre><code>has_many :cards
...
def ordered_cards
  cardsArray = []
  initialCardsArray = cards.to_a

  cardIdsArray = []
  indexHash = {}
  i = 0
  x = 0

  if initialCardsArray.size &lt;= 1
    return initialCardsArray
  end

  while initialCardsArray.size &gt; 0 do
    card = initialCardsArray[i]
    index = cardIdsArray.index(card.after_card_id)

    if card.after_card_id.nil?
      cardsArray.insert(0, card)
      cardIdsArray.insert(0, card.id.to_s)
      initialCardsArray.delete(card)
    elsif !index.nil?
      pos = index + 1
      cardsArray.insert(pos, card)
      cardIdsArray.insert(pos, card.id.to_s)
      initialCardsArray.delete(card)
    else
      i += 1
    end

    if i == initialCardsArray.size
      i = 0
    end

  end

  cardsArray
end
</code></pre>

<p>Any comments or additional solutions would be greatly appreciated! Comments section coming soon!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Preventing Duplicate Content | Rails SEO Tip]]></title>
    <link href="http://micahroberson.com/preventing-duplicate-content/"/>
    <updated>2013-08-17T11:13:00-07:00</updated>
    <id>http://micahroberson.com/preventing-duplicate-content</id>
    <content type="html"><![CDATA[<p>It&rsquo;s useful to allow users to reach your site by visiting both the naked domain, greeksquare.com, as well as the www. prefixed version, www.greeksquare.com. However, this puts search engines in a sticky situation because from their perspective, these are two different sites with the same exact content. Fortunately, there&rsquo;s a simple solution for site&rsquo;s built with any Rack based web server(ie. Ruby on Rails, Sinatra, etc.): <a href="https://github.com/jtrupiano/rack-rewrite">rack-rewrite</a>. Rack-rewrite is a simple middleware for applying rewrite rules (redirects) and we&rsquo;re going to use it to redirect a couple of prefixed domains to the naked domain. By pointing all variations of the same content to one place, we eliminate the competition between the different URLs, and also boost the overall relevancy and popularity.</p>

<p>For this example, I&rsquo;m going to use some snippets from the main Rails app behind <a href="https://greeksquare.com">GreekSquare</a>. Let&rsquo;s begin by adding the rack-rewrite gem:</p>

<pre><code>gem 'rack-rewrite'
</code></pre>

<p>Once the gem is installed, its as simple as adding some rules to production.rb. If you plan on having several rules, it would be best to put this in an initializer.</p>

<pre><code>config.middleware.insert_before(Rack::Lock, Rack::Rewrite) do
  r301 %r{.*}, 'http://greeksquare.com$&amp;', :if =&gt; Proc.new {|rack_env|
    rack_env['SERVER_NAME'] == 'www.greeksquare.com' || rack_env['SERVER_NAME'].include?('herokuapp')
  }
end
</code></pre>

<p>In this example I&rsquo;m rewriting all &lsquo;www.greeksquare.com&rsquo; and &lsquo;greeksquare.herokuapp.com&rsquo; requests to simply be the naked domain &lsquo;greeksquare.com&rsquo;.  Also notice the redirect status code being used, r301, which indicates the site has &lsquo;Moved Permanently&rsquo;. More info on status codes <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">here</a>.</p>

<p>It&rsquo;s also a good idea to make sure you set the Preferred domain in Google&rsquo;s Webmaster Tools. It&rsquo;s easy to get setup with Webmaster Tools, and once you do just visit the Site Settings page where you&rsquo;ll find the form below:</p>

<p><img class="center" src="http://micahroberson.com/images/preferred_url.png"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why You Need a Red Team]]></title>
    <link href="http://micahroberson.com/why-you-need-a-red-team/"/>
    <updated>2013-08-14T08:47:00-07:00</updated>
    <id>http://micahroberson.com/why-you-need-a-red-team</id>
    <content type="html"><![CDATA[<p>A couple of weeks ago, an episode of HBO&rsquo;s <em>The Newsroom</em> brought to light the concept and importance of having a &lsquo;red team&rsquo;. The red team, as described in the show, is a select group of team members who are intentionally left in the dark while a story is flushed out. Once enough &lsquo;proof&rsquo; has been established by the reporters chasing the story, they would then run it by the red team to see if the fresh eyes can poke any holes in it.</p>

<p>The concept certainly isn&rsquo;t new and you probably use it already, but perhaps not as often as you should. Its especially valuable to have a fresh perspective on a website you&rsquo;ve been heads-down on for the past month before releasing for the client. It&rsquo;s not uncommon for the seemingly miniscule assumptions you started the project with, to grow into some pretty large and unpredicted changes by the end, so it&rsquo;s important to make sure the team made the right decisions along the way. The best way to do this is to show a team member the dev site and see if they can identify how all of the requirements have been met.</p>

<p>Any process where someone&rsquo;s work is reviewed by another team member is similar to a red team scenario, but there&rsquo;s one major difference: the reviewer is oftentimes not looking for reasons the work is poor, but rather reasons said work is good or OK. With this comes differing levels of scrutiny, and resultantly not all of the same problems will be identified by the more positive reviewer as those identified by the more negative reviewer. Use your best judgement to determine if a scenario requires the use of a red team, but most situations where the main team has any doubt or made several assumptions are generally good candidates and will see the most benefit.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Absolute Links with Backbone.js and Rails]]></title>
    <link href="http://micahroberson.com/absolute-links-with-backbone-dot-js-and-rails/"/>
    <updated>2013-07-18T09:15:00-07:00</updated>
    <id>http://micahroberson.com/absolute-links-with-backbone-dot-js-and-rails</id>
    <content type="html"><![CDATA[<p>Ideally user&rsquo;s won&rsquo;t ever need to refresh your single page app. With the use of websockets, or simulated websockets via polling, this is avoidable nearly 100% of the time. However, there are some cases where it would be very handy for the user to be able to refresh the page and return to exactly where they were. Perhaps the most important scenario is actually for developers! Making a code change and having to click through several links to actually test the code leaves something to be desired.</p>

<p>To start we need to make sure all Backbone URL/non-API requests get routed to load up the app appropriately. From Rails&#8217; perspective, its rendering the same view, home#index, for every non-API request but making sure the relative path gets passed along with it. To keep it simple, I&rsquo;ve just added a catch-all route, but it may be better to whitelist specific routes that match up with your Backbone.js routes. Notice I&rsquo;m using Devise and also include some &ldquo;api&rdquo; scoped routes to illustrate how this particular app is setup.</p>

<pre><code>devise_for :users
scope :path =&gt; "api" do
  resources :projects
  ...
  resources :posts
end
constraints :format =&gt; "html" do
  match '*path', :controller =&gt; 'home', :action =&gt; 'index'
end
</code></pre>

<p>Within the Home Index view, we just need to ensure we pass down that params[:path] value to the backbone router. This is a snippet from index.html.erb and also where I would include any bootstrapped data that the app would always need before starting up.</p>

<pre><code>&lt;script&gt;
  require([
    'jquery',
    'underscore',
    'backbone',
    'router'
  ], function($, _, Backbone, Router){
    $(function() {
      // Set the current user
      currentUserModel.set(#{Rabl::Renderer.new('users/current_user', current_user, :view_path =&gt; 'app/views').render});
      // Navigate to the current route. One could also pull this from window.location.pathname if no fancy Rails manipulation is req'd
      Router.navigate('&lt;%= params[:path].html_safe %&gt;', {trigger: true});
    });
  });
&lt;/script&gt;
</code></pre>

<p>Assuming all the backbone routes are implemented and setup correctly, this is all that needs to be done! Depending on the type of view, it may need some additional logic to work properly from both an absolute url and also from a relative link within the app. The difference being that it may be dependent on resources being previously loaded which won&rsquo;t be available should the user arrive at the view from an absolute path. There&rsquo;s a couple of options for this scenario: a. Use a Railsy strategy in the router and run a before_filter on every route to load necessary dependencies before even getting to the view code, b. Pass the model to the view if its available and don&rsquo;t if its not, but equip the view to react accordingly. For the former, there&rsquo;s a handy Backbone.js mixin called <a href="https://github.com/boazsender/backbone.routefilter">backbone.routefilter</a>, which will call router.before and/or router.after around each route.</p>

<pre><code>before: () -&gt;
  route = Backbone.history.fragment

  if route.indexOf('dashboard') != -1 || route.indexOf('posts') != -1
    if undefined == currentUserModel || currentUserModel.isNew()
      @listenToOnce currentUserModel, 'change', () =&gt; Backbone.history.loadUrl(route)
      return false
</code></pre>

<p>This before filter simply checks for the currentUserModel to be set and returns false if it isn&rsquo;t while setting up a callback to re-run the same route once the model IS loaded.  The former solution mentioned above might look like this:</p>

<pre><code>render: () -&gt;
  if !@model
    @model = new userModel _id: @user_id
    @listenToOnce @model, 'sync', @renderProfile
    @model.fetch null, { success: () =&gt; @listenTo @model, 'change', @renderProfile }
    usersCollection.add @model
  else
    @listenTo @model, 'change', @renderProfile
    @renderProfile()

  @$el.html _.template(profileTemplate)
  @
</code></pre>

<p>Depending on the app and if there are some common dependencies throughout, the before filter method might work well, while the latter method might work better for other scenarios. Personally I&rsquo;ve used the latter for views that are normally accessed via a list view, ie. a user profile page or detail view, but should still be accessible via the absolute url.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MongoDB Schema Design]]></title>
    <link href="http://micahroberson.com/rails-mongodb-and-embedded-docs/"/>
    <updated>2013-05-12T08:01:00-07:00</updated>
    <id>http://micahroberson.com/rails-mongodb-and-embedded-docs</id>
    <content type="html"><![CDATA[<p>I&rsquo;m a big fan of MongoDB. I understand that it&rsquo;s not great for every dataset out there, nor would I attempt to make it work with a highly relational dataset just because its shiny and new. What I do find rather appealing about MongoDB is the non-rigid document schema and the different mindset you have to have while developing. The non-rigid schema is important because it allows for very agile development and fast iterations. This doesn&rsquo;t mean I condone adding and removing fields like crazy. I think I still make pretty calculated decisions when it comes to adding new fields to a collection just because I&rsquo;ve been in the RDBMS world for so long &ndash; which is a good thing!</p>

<p>The different mindset I mentioned, came about as a result of a conversation I had at <a href="http://www.10gen.com/events/mongodb-san-francisco-2013">MongoDB Days SF</a>. One of the presenters made a point about modeling the data in the database in the same way as you display it in the app. This is a completely different approach than one would take with a classic RDBMS backed application. With an RDBMS, you&rsquo;re most likely going to attempt to normalize the entire schema and then potentially denormalize certain fields out on a case-by-case basis. We do all of this with the assumption that normalization is ideal, and redundancy is bad. I think this allusion comes from two things: a. storage space actually used to be an issue due to hardware constraints and thusly cost. and b. you can relatively easily access any piece of data with the use of joins and/or a number of other techniques in an RDBMS. With MongoDB, I&rsquo;ll layout the design of a particular view and decide what the main domain model is, and if the view is going to be a list format, there&rsquo;s probably some additional metadata from another model that needs to be displayed alongside(i.e. a list of comments, each showing the author thumnail picture and name). At this point, you need to denormalize that metadata in order to avoid the N+1 beast. Although denormalization is necessary for efficient queries, its not all that difficult to maintain nor is it a downside. I much prefer the overall approach to app development with MongoDB and find it much easier to relate the inner-workings to the UI.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Foundation Nav w/ jPanelMenu]]></title>
    <link href="http://micahroberson.com/foundation-nav-w-jpanelmenu/"/>
    <updated>2013-05-04T10:21:00-07:00</updated>
    <id>http://micahroberson.com/foundation-nav-w-jpanelmenu</id>
    <content type="html"><![CDATA[<p><a href="http://foundation.zurb.com/">Foundation</a> provides some excellent out-of-the-box support for responsive layouts and navigation. However, in building out the new mobile interface for <a href="http://www.greeksquare.com/">GreekSquare</a>, we weren&rsquo;t satisfied with the default style.</p>

<p><img class="width-50 right" src="http://micahroberson.com//s3.amazonaws.com/micahroberson/greeksquare-mobile-expanded.png"></p>

<p>This isn&rsquo;t horrible but it also isn&rsquo;t great. I strongly believe a great ui is extremely important and provides for a ton of value to the end-user &ndash; especially in the market we&rsquo;re going after. I set out to find a suitable javascript implementation of a mobile navigation similar to the Facebook mobile app. I tried several different jquery plugins, but they were all extremely invasive and resulted in messy code with clunky javascript animations that didn&rsquo;t fare too well when I tested on an actual device. Finally I came across <a href="http://jpanelmenu.com/">jPanelMenu</a>. jPanelMenu is a lightweight(10kb minified) jquery plugin that lets you pass it any navigation element and flips it around to display in a Facebook style sidenav menu.</p>

<p><img class="width-50 left" src="http://micahroberson.com//s3.amazonaws.com/micahroberson/greeksquare-mobile-new-expanded.png"></p>

<p>Much, much better than before &ndash; both aesthetically, and from a usability standpoint. The end product came out with very few html changes to existing navbar. I ran into a small hiccup when using the fixed implementation of Foundation&rsquo;s navbar, but that was solved by add the following css to shrink it at the same rate as the jPanelMenu expands (ease-in-out at 300ms in my case).</p>

<pre><code>[data-menu-position="open"] .container .fixed {
  left: 200px;
}

.container header .fixed {
  @include transition(ease-in-out left .3s);
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Backbone Collections and Foreign Keys]]></title>
    <link href="http://micahroberson.com/backbone-collections-and-foreign-keys/"/>
    <updated>2013-05-02T08:16:00-07:00</updated>
    <id>http://micahroberson.com/backbone-collections-and-foreign-keys</id>
    <content type="html"><![CDATA[<p>At Arkad, we had the concept of a DataSeries, which was a model that sat at the crossroads of multiple many-to-many relations. Fortunately, we were able to get around modeling ALL of the relations client-side by denormalizing the necessary attributes into the DataSeries json via RABL templates. However, certain client-side foreign key lookups were unavoidable. My first iteration simply used the proxied underscore &lsquo;filter&rsquo;, &lsquo;find&rsquo; and &lsquo;where&rsquo; methods to do the necessary lookups.</p>

<pre><code>getByMappingIdAndCompanyId: function(mapping_id, company_id) {
  var mapping = mappingsCollection.get(mapping_id);
  return _.filter(mapping.get('data_series'), function(ds) {
    var dataSeries = dataSeriesCollection.get(ds.id);
    return (dataSeries !== undefined &amp;&amp; dataSeries.get('company_id') === company_id);
  }, this);
}
</code></pre>

<p>The code above worked, but it was horribly inefficient. In order to find a DataSeries by a mapping_id and company_id, you had to first find the mapping and then look through all the DataSeries it was associated with to find the one with the right company_id. Just so we&rsquo;re all on the same page the associations looked like this:</p>

<pre><code>DataSeries
  belongs_to :company
  has_many :mappings

Mapping
  belongs_to :company
  has_many :data_series

Company
  has_many :data_series
  has_many :mappings
</code></pre>

<p>For the next iteration, I modified the RABL file to include mapping_ids in the DataSeries models, and data_series_ids in the Mapping models. Client-side I hashed the models at creation via &lsquo;add&rsquo;, &lsquo;remove&rsquo;, &lsquo;reset&rsquo; events on the collection.</p>

<pre><code>_hashModel: function(model) {
  _.each(model.get('mapping_ids'), function(id) {
    if(!_.has(this._mappingMap, id))
      this._mappingMap[id] = {};
    this._mappingMap[id][model.get('company_id')] = model;
  }, this);

  if(!_.has(this._companyMap, model.get('company_id')))
    this._companyMap[model.get('company_id')] = {};
  this._companyMap[model.get('company_id')][model.id] = model;
},
</code></pre>

<p>There was two main scenarios for accessing the models: by both mapping_id and company_id, and just by company_id. So I created a hash to handle each case, in order to keep the lookup time constant. Although this pseudo-map isn&rsquo;t nearly the same as a GLib hash table or STL Map, it&rsquo;s safe to assume that lookups are O(1). If you&rsquo;re going to be doing more lookups than hashing(adding keys is slow), its safe to use these techniques and worth the additional overhead to hold the &lsquo;map&rsquo; in memory.</p>

<p>More recently, I&rsquo;ve come across a similar scenario that involved model lookup by slug rather than id. MongoDB provides some unsightly ID&rsquo;s so I employed the <a href="https://github.com/digitalplaywright/mongoid-slug">mongoid_slug</a> gem to handle slugging on the model&rsquo;s name attribute. Mongoid-slug provides an overridden &lsquo;find&rsquo; method on the model, but using Backbone with a Single Page App, meant I could either always force a model lookup to the backend, or check the client-side collection first(ideal). However, due to the large number of models potentially present client-side, I wanted to avoid a call to _.find for a matching name attribute. Here&rsquo;s the extended BaseCollection my collection extends <a href="https://gist.github.com/micahroberson/5493159">https://gist.github.com/micahroberson/5493159</a></p>

<pre><code>define [
  'jquery', 'jqueryui', 'underscore', 'backbone'
], 
($, jqueryui, _, Backbone) -&gt;

  class BaseCollection extends Backbone.Collection

    initialize: () -&gt;
      @bindHashEvents()

    # e.g.
    # hash_keys: [
    #   'subject',
    #   'message',
    #   'buildSlug' # where buildSlug: () -&gt; "#{@get('name').downcase().replace(/\s/g,'-')}"
    # ]
    hash_keys: []

    # key is the attribute originally set via hash_keys(e.g. 'name'), lookup_val is the search term (e.g. 'Frank')
    retrieveFromHash: (key, lookup_val) -&gt;
      if !key then return []

      @["_#{key}_hash"][lookup_val]

    bindHashEvents: (hash_keys) -&gt;
      # Check for hash keys a la delegateEvents paradigm
      if !(hash_keys || (hash_keys = _.result(this, 'hash_keys'))) then return @

      _.each hash_keys, (key) =&gt;
        # initialize hash
        @["_#{key}_hash"] = {}

        hashSingle = (model) =&gt;
          # first check if key is method defined on the model, otherwise assume its an attribute on model
          hk = if typeof model[key] == 'function' then model[key]() else model.get(key)
          @["_#{key}_hash"][hk] = model unless !hk

        @listenTo @, 'add', hashSingle

        @listenTo @, 'reset', (collection) =&gt;
          @["_#{key}_hash"] = {}
          _.each(@models, hashSingle, @)

        @listenTo @, 'remove', (model) =&gt;
          hk = if typeof model[key] == 'function' then model[key]() else model.get(key)
          delete @["_#{key}_hash"][hk]
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Not Another Productivity Post]]></title>
    <link href="http://micahroberson.com/not-another-productivity-post/"/>
    <updated>2012-12-01T13:21:00-08:00</updated>
    <id>http://micahroberson.com/not-another-productivity-post</id>
    <content type="html"><![CDATA[<p>Note: This is not a bunch of tips on how to block Facebook or why you should be setting timers to keep yourself focused. Its merely a series of observations and hypotheses I made over the course of several client-projects at ReadyApps.</p>

<p>Our very first client came back for additional projects a number of times. While working on the most recent of these, James pointed out that we are always much more efficient when working on projects for this client than anything else. I gave it some thought, and came up with a few main reasons:</p>

<ol>
<li><p>The scope is always small and well defined. Sometimes its a series of small updates, sometimes its a whole new feature that requires end-to-end code changes, but its always well thought out. This client knows, for the most part, exactly what they want added and/or changed and how they would like it to function. And if they don&rsquo;t have it down pat, we clear it up in the meeting beforehand. This one can&rsquo;t always be replicated, because oftentimes the client doesn&rsquo;t know what they want. However, that just means we&rsquo;re required to take upon that role and set the requirements and guidelines for ourselves.</p></li>
<li><p>We know the codebase inside and out. We spent how many months on that first iteration? This may have been the first project we ever did and it may not be quite up to par with our latest endeavors(we tend to stay away from ASP.NET these days), but we still know whats going on and how to add new features. Part of the reason is that we started with a very simple concept and continuously built on top of it. With each iteration we were doing pretty much the same thing. Add an ASP gridview , make a few database changes, bind the table with a SQL datasource, etc. This repetition and constant contact with the codebase is what established our familiarity.</p></li>
<li><p>We make sure we work on it together. This one&rsquo;s big. And we&rsquo;ve know this for a while, but this project is still the only one we do it on. We hate the thought of working on that codebase, so we go in with the intention of banding together and getting shit done. And its never as bad as it seems, its just not as fun as working on something newer(and not ASP.NET). Its like going to the gym &ndash; you can get a decent workout going by yourself, but you&rsquo;re never going to be able to push yourself like you can with someone spotting you and trying to out-benchpress you.</p></li>
<li><p>&lsquo;With the intention of getting shit done&rsquo;. This is another tremendously important factor in the productivity equation. There&rsquo;s big difference between starting a project with the mindset of <i>just casually going at it with no real direction</i> vs. <i>taking calculated steps to hit all of the requirements and ship something</i>. The latter results in a productivity increase of 1000x (I ran the numbers&hellip;). We shouldn&rsquo;t start coding up a feature until we have some direction and we also shouldn&rsquo;t quit working on a feature until its done and functioning. This doesn&rsquo;t mean we don&rsquo;t switch projects, it means within a single project, we should start a feature and make sure its done and ready to ship before moving on. This can be applied all sorts of tasks, not just coding.</p></li>
</ol>


<p>So what do we take away from all of this? Two things. The fact that we are most efficient on this one specific codebase is just wrong. It&rsquo;s actually ridiculous. We definitely don&rsquo;t know the ASP.NET more than PHP or Ruby, and it definitely doesn&rsquo;t offer up much in regards to &lsquo;rapid prototyping&rsquo;. Its purely how we work on the projects and the mindset we go in with. Second thing. Make sure the feature-sets are well defined, and there&rsquo;s never a single developer completing the entire project.</p>
]]></content>
  </entry>
  
</feed>
